name: Process Awin CSV

on:
  # Manual trigger
  workflow_dispatch:
    inputs:
      batch_size:
        description: 'Batch size for processing'
        required: false
        default: '50'
        type: number
      max_products:
        description: 'Maximum products to process (0 = no limit)'
        required: false
        default: '0'
        type: number
      force_full_run:
        description: 'Force full dataset processing'
        required: false
        default: false
        type: boolean

  # Daily at midnight UTC
  schedule:
    - cron: '0 0 * * *'

jobs:
  process-csv:
    runs-on: ubuntu-latest
    timeout-minutes: 720  # 12 hours max

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Set processing parameters
      id: params
      run: |
        if [ "${{ github.event_name }}" = "schedule" ]; then
          echo "Scheduled run - processing full dataset"
          echo "batch_size=50" >> $GITHUB_OUTPUT
          echo "max_products=0" >> $GITHUB_OUTPUT
        else
          echo "Manual run with custom parameters"
          echo "batch_size=${{ inputs.batch_size }}" >> $GITHUB_OUTPUT
          echo "max_products=${{ inputs.max_products }}" >> $GITHUB_OUTPUT
        fi

    - name: Download CSV data
      run: |
        echo "Checking for CSV file in GitHub releases..."

        # First check if there's a latest release
        RELEASE_DATA=$(curl -s https://api.github.com/repos/${{ github.repository }}/releases/latest)

        # Check if the API returned valid data
        if [ "$(echo "$RELEASE_DATA" | jq -r '.message // empty')" = "Not Found" ]; then
          echo "‚ùå No releases found in repository. Please create a release and upload datafeed_2525445.csv"
          exit 1
        fi

        # Extract CSV URL safely
        CSV_URL=$(echo "$RELEASE_DATA" | jq -r '.assets[]? | select(.name == "datafeed_2525445.csv") | .browser_download_url' 2>/dev/null || echo "")

        if [ -z "$CSV_URL" ] || [ "$CSV_URL" = "null" ]; then
          echo "‚ùå CSV file 'datafeed_2525445.csv' not found in the latest release assets."
          echo "üìã Available assets in latest release:"
          echo "$RELEASE_DATA" | jq -r '.assets[]?.name // "No assets found"' 2>/dev/null || echo "  - Unable to list assets"
          echo ""
          echo "üì§ Please:"
          echo "   1. Go to https://github.com/${{ github.repository }}/releases"
          echo "   2. Create a new release or edit the latest release"
          echo "   3. Upload datafeed_2525445.csv as a release asset"
          echo "   4. Make sure the filename matches exactly: 'datafeed_2525445.csv'"
          exit 1
        fi

        echo "‚úÖ Found CSV file: $CSV_URL"
        echo "üì• Downloading CSV..."
        wget -O datafeed_2525445.csv "$CSV_URL"

        # Verify download
        if [ ! -f "datafeed_2525445.csv" ]; then
          echo "‚ùå Failed to download CSV file"
          exit 1
        fi

        FILE_SIZE=$(stat -f%z datafeed_2525445.csv 2>/dev/null || stat -c%s datafeed_2525445.csv 2>/dev/null || echo "unknown")
        echo "‚úÖ CSV downloaded successfully. Size: $FILE_SIZE bytes"

    - name: Create .env file
      run: |
        echo "SUPABASE_URL=${{ secrets.SUPABASE_URL }}" >> .env
        echo "SUPABASE_KEY=${{ secrets.SUPABASE_KEY }}" >> .env

    - name: Run processing script
      env:
        BATCH_SIZE: ${{ steps.params.outputs.batch_size }}
        MAX_PRODUCTS: ${{ steps.params.outputs.max_products }}
      run: |
        echo "Starting processing with batch_size=${{ steps.params.outputs.batch_size }}, max_products=${{ steps.params.outputs.max_products }}"
        python process_awin_csv.py

    - name: Upload logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: processing-logs-${{ github.run_id }}
        path: |
          awin_processor.log
          *.log
        retention-days: 7

    - name: Notify completion
      if: always()
      run: |
        STATUS="${{ job.status }}"
        RUN_TYPE="${{ github.event_name }}"
        TIMESTAMP=$(date -u +"%Y-%m-%d %H:%M:%S UTC")

        echo "Processing completed at $TIMESTAMP"
        echo "Status: $STATUS"
        echo "Run type: $RUN_TYPE"
        echo "Run ID: ${{ github.run_id }}"

        # You can add webhook notifications here
        # Example for Slack/Discord webhook:
        # curl -X POST -H 'Content-type: application/json' \
        #   --data "{\"text\":\"Awin processing $STATUS at $TIMESTAMP (Run: $RUN_TYPE)\"}" \
        #   ${{ secrets.NOTIFICATION_WEBHOOK_URL }}

        if [ "$STATUS" = "success" ]; then
          echo "‚úÖ Processing completed successfully"
        else
          echo "‚ùå Processing failed - check logs for details"
        fi

